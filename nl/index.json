[{"content":"Op dringend verzoek van Stichting BREIN is GEITje vanaf heden niet meer beschikbaar. Alle model files zijn verwijderd uit mijn HuggingFace repos1.\nGEITje was een Nederlandstalig groot open taalmodel met 7 miljard parameters, gebaseerd op Mistral 7B. Het was (verder) getraind op 10 miljard tokens aan Nederlandstalige tekst. Daardoor heeft het beter Nederlands geleerd, en meer kennis over Nederlandse onderwerpen.\nZoals vermeld in de README is GEITje eind 2023 onder meer getraind op gedeeltes van het Nederlandse Gigacorpus. Stichting Brein stelt dat sommige van die subsets van het Gigacorpus auteursrechtelijk beschermd materiaal bevatten uit illegale bron. Zij hebben daarom in augustus 2024 het gehele Gigacorpus offline laten halen.\nBrein heeft mij laten weten dat, naar hun mening, volgens geldende wet- en regelgeving het model GEITje daarom ook offline gehaald moet worden. Ik ben door auteursrechten-experts ervan verzekerd dat dit niet zo zwart/wit is als gesteld. Maar zij vertellen me ook dat er nog veel juridische vragen in Europa hierover onbeantwoord zijn. Ik kan het me niet veroorloven om een lange en vooral zeer dure rechtszaak te voeren om die vragen wel beantwoord te krijgen. GEITje is immers een niet-commercieel, wetenschappelijk hobbyproject. Daarom voldoe ik aan het verzoek van Brein.\nSinds de release van GEITje zijn er ook wetenschappelijke artikelen geschreven waarin GEITje wordt gebruikt om onderzoek te doen naar Large Language Models in het Nederlands. Ik had gewild dat GEITje voor wetenschappers beschikbaar bleef om de wetenschappelijke reproduceerbaarheid van hun onderzoek te kunnen garanderen. Maar helaas: gesprekken daarover met Brein zijn op niets uitgelopen.\nIk ben blij met de vele positieve reacties die ik het afgelopen jaar heb mogen ontvangen. Het was ook erg mooi om te zien hoe GEITje het afgelopen jaar velen heeft weten te inspireren. GEITje heeft laten zien dat er een alternatief van Nederlandse en Vlaamse bodem kan bestaan voor de gesloten taalmodellen van buitenlandse techgiganten. GEITje is inmiddels niet meer alleen: er bestaan nu open Nederlandstalige LLMs in vele vormen en smaken, getraind op allerlei verschillende bronnen.\nWat mij betreft ligt de toekomst van Europese AI nog steeds in open source AI. Alleen als een AI vrij te gebruiken is, door iedereen bestudeerd kan worden en voor elk doel vrij te modificeren en delen is, dán pas kunnen we spreken over soevereine AI. De Franse en Spaanse overheden gingen ons daarin al voor en trainden volledig open source modellen met overheidsgeld. Een weg naar een écht open source Nederlandstalig AI-landschap ligt nog altijd voor ons open.\nVerwijderd zijn alle .safetensors files (de gewichten van het model) van GEITje-7B en alle door mij getrainde afgeleide chatmodellen, inclusief die van alle tussentijdse training checkpoints. Ook de optimizer.pt-bestanden van de checkpoints zijn verwijderd. Daarnaast zijn door alle door mij gemaakte conversies van de modellen (zoals .gguf files) ook verwijderd.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://goingdutch.ai/nl/posts/geitje-takedown/","summary":"Op dringend verzoek van Stichting BREIN is GEITje vanaf heden niet meer beschikbaar. Alle model files zijn verwijderd uit mijn HuggingFace repos1.\nGEITje was een Nederlandstalig groot open taalmodel met 7 miljard parameters, gebaseerd op Mistral 7B. Het was (verder) getraind op 10 miljard tokens aan Nederlandstalige tekst. Daardoor heeft het beter Nederlands geleerd, en meer kennis over Nederlandse onderwerpen.\nZoals vermeld in de README is GEITje eind 2023 onder meer getraind op gedeeltes van het Nederlandse Gigacorpus.","title":"Het einde van GEITje 1"},{"content":"Deze week had ik de eer om te gast te zijn in de podcast van Alexander Klöpping en Wietse Hage: Poki – de Podcast over Kunstmatige Intelligentie.\nWe hadden een goed gesprek over GEITje, het finetunen van Large Language models in het algemeen en voor het Nederlands in het bijzonder. We hebben ongeveer een half uur gesproken, en het gesprek is bijna integraal in de podcast beland. Inclusief wat nu wel een klassieker moet worden: de Bassietest.\nJe kunt de aflevering hier beluisteren, of zoek naar zelf naar \u0026ldquo;Poki\u0026rdquo; in je favoriete podcast-app.\n","permalink":"https://goingdutch.ai/nl/posts/poki-geitje/","summary":"Deze week had ik de eer om te gast te zijn in de podcast van Alexander Klöpping en Wietse Hage: Poki – de Podcast over Kunstmatige Intelligentie.\nWe hadden een goed gesprek over GEITje, het finetunen van Large Language models in het algemeen en voor het Nederlands in het bijzonder. We hebben ongeveer een half uur gesproken, en het gesprek is bijna integraal in de podcast beland. Inclusief wat nu wel een klassieker moet worden: de Bassietest.","title":"Interview in de Poki-podcast: \"Het Nederlandse taalmodel: GEITje ft. Edwin Rijgersberg\""},{"content":"De tweede van een serie posts over vragen die ik over GEITje krijg.\n\u0026ldquo;Waarom de naam GEITje?\u0026rdquo;\nMuppets, koeien en zeerobben De naam \u0026ldquo;GEITje\u0026rdquo; zat eigenlijk al veel langer in mijn hoofd als naam voor een Nederlandstalig groot taalmodel.\nNaamgeving in de wereld van de taalmodellen is onderhevig aan interessante trends. In 2017 begon de Muppet-generatie van taalmodellen met Allen Institute for AI\u0026rsquo;s ELMo, gevolgd door Googles doorbraak BERT. Uiteraard lieten ERNIE, Grover en BigBIRD niet lang op zich wachten. Ze werden opgevolgd door Facebooks verbeterde variant van BERT: RoBERTa.\nWelke naam moet je aan de Nederlandstalige varianten van deze taalmodellen geven? Wietse de Vries et al. kozen voor hun Nederlandstalige BERT-model simpelweg voor \u0026ldquo;BERTje\u0026rdquo;. Simpel, maar doeltreffend: de \u0026ldquo;-je\u0026rdquo;-uitgang is meteen herkenbaar als Nederlands, en het voegt een element van schattigheid toe. Het bijbehorende logo, een oer-Hollandse koe, is ook een schot in de roos.\nPieter Delobelle et al. kozen voor een andere strategie bij hun Nederlandstalige variant van RoBERTa. Zij hebben hun model zichzelf een naam laten geven, door het model het masker in \u0026lt;mask\u0026gt;BERT te laten voorspellen. Daar kwam de typisch Nederlandse naam RobBERT uit. Met bijbehorend schattig logo van een zeerob verkleed als Bert uit Sesamstraat, uiteraard.\nLama\u0026rsquo;s en andere kameelachtigen Na de komst van ChatGPT eind 2022 (zonder schattig logo, helaas) kwamen de open source alternatieven snel op gang. Meta gaf het startschot met LLaMA (geen logo), gevolgd door een serie finetunes die van LLaMA een chatbot maakten: met onder andere Stanford Alpaca (fancy alpaca met zonnebril) en Vicuña (abstract logo door Stable Diffusion 2.1).\nHelaas heeft de lama niet zo\u0026rsquo;n heel uitgebreide familie. Na de alpaca en vicuña heb je nog de Guanaco, maar daarna zijn de lamini wel op. Namen van overige kameelachtigen zijn verder nooit echt aangeslagen.\nValken en verre windstreken Het dierenthema bleef nog even hangen. Eventjes was het model du jour Falcon, van het Technology Innovation Institute (zeg maar de TNO van Abu Dhabi). Logo: een polygoon-tekening van een valk.\nHet volgende open source model dat een plek in de zeitgeist veroverde was Mistral 7B, gemaakt door de ietwat mysterieuze Franse startup Mistral AI. Model en bedrijf zijn vernoemd niet naar een dier, maar naar de mistral: de krachtige noordelijke wind in Oost-Frankrijk. Bijbehorend logo heeft niets met een wind te maken, maar heeft wel flinke jaren negentig-WordArt-vibes.\nEen groot Nederlands taalmodel gebaseerd op Mistral Dus: zeg het maar. Je traint een Nederlandstalig taalmodel, dat je baseert op Mistral 7B. Hoe ga je het noemen?\nIk heb nog even overwogen om een variant op Mistral te gebruiken. In Nederland hebben we immers ook wel iets met wind. Maar op één of andere manier bekten de modellen Westenwind 7B en Noordwester 7B toch niet zo goed.\nDan maar terug naar het dierenthema. Een geit, een dier dat je op elke kinderboerderij zult vinden. Een dier dat gulzig alles opvreet wat je hem voert, en daarna hard begint te blaten. Wat is er toepasselijker voor een taalmodel? Een geitje, want 7 miljard is helemaal niet zo groot als sommige andere modellen. En het past mooi bij BERTje.\nGEITje dus. Met schattig logo, bedacht door ChatGPT.\nEn die hoofdletters dan? Goede vraag. Als je echt wil kan je vast wel een zin bedenken waar de letters G, E, I en T opeenvolgend in voorkomen. GEneratIeve Transformer is de beste die ik tot nu toe heb kunnen verzinnen, maar kan je zelf vast beter.\n","permalink":"https://goingdutch.ai/nl/posts/naming-geitje/","summary":"De tweede van een serie posts over vragen die ik over GEITje krijg.\n\u0026ldquo;Waarom de naam GEITje?\u0026rdquo;\nMuppets, koeien en zeerobben De naam \u0026ldquo;GEITje\u0026rdquo; zat eigenlijk al veel langer in mijn hoofd als naam voor een Nederlandstalig groot taalmodel.\nNaamgeving in de wereld van de taalmodellen is onderhevig aan interessante trends. In 2017 begon de Muppet-generatie van taalmodellen met Allen Institute for AI\u0026rsquo;s ELMo, gevolgd door Googles doorbraak BERT. Uiteraard lieten ERNIE, Grover en BigBIRD niet lang op zich wachten.","title":"GEITje FAQs: Waarom de naam \"GEITje\"?"},{"content":"De eerste van een serie posts over vragen die ik over GEITje krijg.\n\u0026ldquo;Waarom heb je een taalmodel gemaakt?\u0026rdquo; Die vraag heb ik de afgelopen weken meermaals gekregen. Meestal meteen gevolgd door een vervolgvraag: \u0026ldquo;ChatGPT bestaat toch al?\u0026rdquo; Geen gekke vraag, eigenlijk. Hieronder mijn drie belangrijkste redenen:\n1. Omdat open modellen nodig zijn ChatGPT doet het geweldig in het Nederlands. Als je een toepassing hebt waar je een LLM voor wilt proberen, pak vooral ChatGPT of één van de OpenAI APIs. Ze zijn goed en goedkoop, en je hebt in no time een oplossing in elkaar gedraaid. En mocht je een uitdagende usecase hebben: je kunt nu zelfs hun modellen finetunen op jouw data. Maar er zijn ook nadelen.\nTen eerste zijn er altijd gevallen waarin je jouw data niet naar OpenAI wilt, kunt of mag sturen. Zorgvuldig omgaan met gegevens is belangrijk, zeker met het oog op de AVG en de komende AI-Verordening. Daarom ben je al snel gebonden aan modellen die je lokaal op je eigen infrastructuur kunt draaien, om zo je private data privé te houden.\nTen tweede is OpenAI, de steeds ironischer wordende bedrijfsnaam ten spijt, helemaal niet zo open. Ze vertellen je niet op welke bronnen hun modellen getraind zijn, of wat voor soort filtering ze toepassen, of zelfs niet hoe groot hun modellen zijn. Het enige wat je krijgt is een black box op hun servers waar je tegenaan kunt praten, en een technical report zonder betekenisvolle technische rapportages. Als je onderzoek wilt doen naar het model, bijvoorbeeld om te bepalen of er bepaalde biases aanwezig zijn die voor jouw toepassing van belang zijn, dan heb je pech. Het enige wat je kunt doen is tekst naar de black box sturen en de tekst die je terugkrijgt bestuderen, maar alle andere geavanceerdere opties zijn van tafel. Een open model kan je zo uitgebreid bestuderen als je zelf wil.\nTenslotte bieden open modellen een kans om voort te bouwen op elkaars werk, en daar weer iets voor terug te geven. Zo kom je gezamenlijk tot een veel hoger niveau dan waar iedereen in z\u0026rsquo;n eentje toe in staat is, en daar is iedereen weer bij gebaat.\nOpen modellen zijn dus nodig, en goed nieuws: ze zijn booming in 2023! Maar het Nederlands bleef helaas achter, aangezien de open source-wereld zich vooral richtte op Engels, Chinees en programmeertalen. Een bekend verhaal voor wie mijn eerdere blogpost over BLOOM heeft gelezen, al waren er deze keer wel al initiatieven die de goede richting op gingen.\n2. Omdat het kan Wat is er dan voor nodig om een Nederlands taalmodel te maken? En is dat mogelijk om als hobby-projectje te doen? Nou, nee, niet als je het vanaf de grond af wilt opbouwen. Meta heeft voor het trainen van Llama 2 7B 184.320 GPU-uur gebruikt, wat ongeveer 74.000 kWh verstookt heeft. Dergelijke budgetten zijn onbereikbaar voor de GPU-poor. En, stel, je weet ergens gratis rekencapaciteit vandaan weten te toveren. Dan moet je nog ergens de 2.000 miljard tokens aan Nederlandstalige tekst vandaan weten te halen om tot hetzelfde de hoeveelheid tekst te komen als Meta voor LLaMA 2 heeft gebruikt. En als je dan een foundation model hebt getraind, dan moet je ook nog eens tienduizenden gesprekken (laten) maken om je foundation model tot een echte chatbot te trainen.\nMaar wat als je enkele slimme en praktische keuzes maakt? Wat als je niet begint bij nul? Wat als je voortbouwt op bestaande open source modellen, zoals LLaMA 2 of Mistral? Ondanks dat het waarschijnlijk niet de bedoeling was, is er blijkbaar toch genoeg Nederlandstalige tekst in hun trainingsdata geslopen om een aardig woordje Nederlands te kunnen. Niet genoeg om er een langere coherente conversatie mee te houden, en de kennis over Nederlandse of Vlaamse onderwerpen van die modellen is zeer beperkt, maar het is zeker beter dan beginnen met niets. Het enige wat je op moet geven is wat transparantie. Het is helaas zo dat ook van deze open source modellen weinig bekend is over op welke data ze getraind zijn.\nAls je met zo\u0026rsquo;n voorgetraind model begint, dan heb je ook niet zulke gigantische hoeveelheden tekst nodig om je taalmodel te trainen. GEITje is getraind op 10 miljard tokens Nederlandstalige tekst. Tot een paar honderd miljard tokens is het relatief makkelijk om aan materiaal te komen. Datasets van chatgesprekken om een chatbot op te trainen zijn er nauwelijks voor het Nederlands, maar ze zijn wel overvloedig beschikbaar in het Engels. Door GPT-3.5 als vertaler te gebruiken kan je voor minder dan 100 euro zo tienduizend gesprekken omzetten van het Engels naar het Nederlands.\nDan moet je nog aan GPUs zien te komen. Ja, die zijn extreem duur om te kopen. En ze zijn ook duur om te huren bij gangbare cloudproviders als AWS of Azure. Maar als je gaat voor een cloudprovider die van GPUs zijn specialiteit gemaakt heeft, dan kan het allemaal een stuk goedkoper. Providers als Lambda Labs en RunPod kunnen tot wel 80 % goedkoper zijn. Als je er een GPU te pakken weet te krijgen tenminste, want vaak zijn ze allemaal bezet. Daarover in een latere blogpost meer.\n3. Omdat het leuk en leerzaam is De derde reden is misschien wel de belangrijkste reden. Het is gewoon een ontzettend leuk en leerzaam project!\nTaalmodellen hebben al langer mijn interesse, en die is het afgelopen jaar met doorbraak van de LLMs alleen maar gegroeid. Er over lezen is leerzaam, en ze zelf toepassen nog leerzamer. Maar niets geeft je meer inzicht in een model dan het zelf te moeten trainen.\nOm GEITje te kunnen maken heb ik me moeten verdiepen in de verschillende foundation models en hun voor- en nadelen. Ik heb me moeten verdiepen in de kwaliteit van datasets, en ik heb beslissingen moeten nemen over het selecteren van data. Ik heb moeten uitzoeken wat de verschillende manieren van evalueren van modellen zijn, en welke van toepassing zijn voor het Nederlands. Ik heb datasets bestaande uit gigantische tekstbestanden moeten parsen en opsplitsen in losse documenten. Ik heb trainingscode moeten schrijven, waardoor ik meer inzicht heb gekregen in de details van 🤗 Hugging Face Transformers, accelerate en Datasets. Ik heb een steeds groter worden README moeten schrijven en onderhouden. Ik heb moeten experimenteren met verschillende manieren van trainen op meerdere GPUs tegelijk, om zo tot de meest kosten-efficiënte methode te komen. Ik heb voor het eerst trainings-grafieken live in de cloud kunnen zien bij Weights \u0026amp; Biases. Ik heb een Gradio-interface aangepast om een live demo van GEITje chat aan te kunnen bieden.\nEn tenslotte heb ik simpelweg trainingscode moeten debuggen en werkend moeten krijgen in de cloud op gehuurde GPUs. Het is een hele ervaring om een probleem op te lossen terwijl je de minuten niet ziet alleen ziet aftikken op de klok, maar ook direct op je eigen creditcard.\n","permalink":"https://goingdutch.ai/nl/posts/why-geitje/","summary":"De eerste van een serie posts over vragen die ik over GEITje krijg.\n\u0026ldquo;Waarom heb je een taalmodel gemaakt?\u0026rdquo; Die vraag heb ik de afgelopen weken meermaals gekregen. Meestal meteen gevolgd door een vervolgvraag: \u0026ldquo;ChatGPT bestaat toch al?\u0026rdquo; Geen gekke vraag, eigenlijk. Hieronder mijn drie belangrijkste redenen:\n1. Omdat open modellen nodig zijn ChatGPT doet het geweldig in het Nederlands. Als je een toepassing hebt waar je een LLM voor wilt proberen, pak vooral ChatGPT of één van de OpenAI APIs.","title":"GEITje FAQs: Waarom ik GEITje heb gemaakt"},{"content":"Het is nu meer dan twee weken geleden dat ik GEITje 7B heb ge-opensourced. Het was een spannend moment, zeker omdat dit mijn eerste grote open source bijdrage is. Maar ik vind het heel leuk om te zien hoe enthousiast alle reacties zijn geweest!\nGEITje is een Nederlandstalig groot open taalmodel met 7 miljard parameters, gebaseerd op Mistral 7B. Het is (verder) getraind op 10 miljard tokens aan Nederlandstalige tekst. Daardoor heeft het beter Nederlands geleerd, en meer kennis over Nederlandse onderwerpen.\nEr zijn al allerlei mensen mee aan de slag gegaan voor hun toepassingen, waarvan we hopelijk binnenkort de eerste resultaten gaan zien. Bram VanRoy heeft hem toegevoegd aan het Open Dutch LLM Evaluation Leaderboard, en ook meteen opgenomen in zijn nieuwste paper: Language Resources for Dutch Large Language Modelling. Dank daarvoor!\nLinks De belangrijkste links op een rijtje:\nGEITje op GitHub: Uitgebreide README over het model, en de broncode natuurlijk. 🤗 Hugging Face Models voor directe toegang tot de modellen: GEITje 7B GEITje 7B chat GEITje 7B chat v2 Chat met GEITje 7B chat v2 in 🤗 Hugging Face Spaces (dank aan Hugging Face voor de community GPU grant!) Overzicht op 🤗 Hugging Face Collections met alle modellen, gekwantiseerde varianten en de datasets. FAQs Een (nog lopende) serie blogposts over veelgestelde vragen over GEITje:\nGEITje FAQs: Waarom ik GEITje heb gemaakt GEITje FAQs: Waarom de naam \u0026ldquo;GEITje\u0026rdquo;? ","permalink":"https://goingdutch.ai/nl/posts/introducing-geitje/","summary":"Het is nu meer dan twee weken geleden dat ik GEITje 7B heb ge-opensourced. Het was een spannend moment, zeker omdat dit mijn eerste grote open source bijdrage is. Maar ik vind het heel leuk om te zien hoe enthousiast alle reacties zijn geweest!\nGEITje is een Nederlandstalig groot open taalmodel met 7 miljard parameters, gebaseerd op Mistral 7B. Het is (verder) getraind op 10 miljard tokens aan Nederlandstalige tekst. Daardoor heeft het beter Nederlands geleerd, en meer kennis over Nederlandse onderwerpen.","title":"GEITje 7B: een groot open Nederlands taalmodel"},{"content":"Drie vrijwilligers. Een paar weken aan werk. Dat is wat er nodig was om een taal op te nemen in BigScience BLOOM, het open meertalige taalmodel met maar liefst 176 miljard parameters dat halverwege 2022 uitkwam. Het moest een open, meertalig alternatief voor GPT-3 worden. Uiteindelijk zijn er 46 talen van over de hele wereld beland in de dataset waarmee BLOOM getrained is. Ook relatief kleine talen als het Baskisch en het Catalaans kregen het voor elkaar om opgenomen te worden. Het Nederlands niet. Hoe kan dat?\nBigScience, big dreams Het begon allemaal in 2021. Een groep van meer dan 1.000 onderzoekers had zich verenigd in het virtuele onderzoekscollectief BigScience. Vermoedelijk getriggerd door de capaciteiten van GPT-3 en bezorgd om de opkomst van de grote taalmodellen die door de grote techbedrijven voor angstvallig voor zichzelf gehouden worden, deden ze vanaf mei 2021 mee aan een éénjarige open onderzoeks-workshop op het gebied van meertalige grote taalmodellen.\nGefinancierd door de Franse overheid en de Frans-Amerikaanse start-up Hugging Face \u0026mdash; één van de hotste bedrijven op het gebied van AI \u0026mdash; wilden ze twee dingen bereiken:\neen zeer grote meertalige tekst-dataset samenstellen van hoge kwaliteit, later ROOTS genoemd; en daarmee een zeer groot meertalig taalmodel trainen dat GPT-3 naar de kroon kon steken: BLOOM. Zij wilden dit zo open mogelijk doen. Het model moest door iedereen te downloaden zijn, zodat je het kunt gebruiken voor toepassingen waar je gesloten modellen als GPT-3 niet voor kunt gebruiken. Als je bijvoorbeeld vertrouwelijke data hebt die je niet naar een Amerikaans techbedrijf wil sturen. Of als je het model wilt onderzoeken op mogelijke biases voordat je het inzet. Of als je gewoon uit principe wilt weten op welke data het model wel en niet gezien heeft in de trainingsfase.\nOm dit voor elkaar te krijgen zijn onderzoekers betrokken vanuit allerlei verschillende vakgebieden en zijn dataset en model vanuit meerdere gezichtspunten onderzocht:\n‍During the workshop, the participants plan to investigate the dataset and the model from all angles: bias, social impact, capabilities, limitations, ethics, potential improvements, specific domain performances, carbon impact, general AI/cognitive research landscape.\nHet hele initiatief is ook uitvoerig beschreven in drie losse wetenschappelijk papers: over het proces, over de dataset en over het model.\nDe BigScience werkgroepen. Akiki, Christopher, et al. \u0026ldquo;BigScience: A case study in the social construction of a multilingual large language model.\u0026rdquo; arXiv preprint arXiv:2212.04960 (2022).\nBLOOM: open, ethisch en klimaatvriendelijk Het resultaat: BLOOM, het BigScience Large Open-science Open-access Multilingual Language Model, gelanceerd in juli 2022. Een groot open taalmodel van 176 miljard parameters dat getraind is op 46 verschillende talen (en 13 verschillende programmeertalen). Het is voor iedereen vrij te downloaden, te bestuderen en te gebruiken1. En niet alleen het uiteindelijke model is beschikbaar, maar ook tussentijdse checkpoints van het model van tijdens het trainen zijn met iedereen gedeeld.\nHet model is in 117 dagen getraind op ruim 3.000 GPUs van de Franse Jean Zay supercomputer. Kosten? Ongeveer 3 miljoen euro. De Franse supercomputer is ook de bron van de claim van de klimaatvriendelijkheid van het model. BigScience gaat er namelijk prat op dat de benodigde elektriciteit grotendeels opgewekt is met kernenergie. Het trainen van het model heeft daardoor een lage CO2-uitstoot met zich meegebracht.\nDe Jean Zay Supercomputer. © Photothèque CNRS/Cyril Frésillon\nDe focus op openheid en ethiek leverde lof op vanuit de academische wereld. Onderzoekers van de Stanford University publiceerden recent een onderzoek naar grote taalmodellen. Ze brachten in kaart welke van de grote taalmodellen nu al het best voldoen aan de eisen uit de voorlopige tekst van de EU AI Act: de Verordening Kunstmatige Intelligentie van de Europese Unie. BLOOM scoorde verreweg het best. Ook de Radboud Universiteit deed een vergelijkend onderzoek naar de openheid van taalmodellen (leaderboard, paper). Het meest open model? Wederom BLOOM.\nIn 2022 werd het mode om elk groot taalmodel als een foundation model te beschouwen, en zo\u0026rsquo;n model te finetunen op chatconversaties om een interactief model te maken á la OpenAI\u0026rsquo;s InstructGPT. Begin november 2022 is er daarom ook nog een chat-variant van BLOOM uitgebracht: BLOOMZ (website, paper, GitHub). De buzz daaromheen is helaas een beetje verloren gegaan in het geweld van ChatGPT, dat nog geen vier weken later werd gelanceerd.\nScores van grote taalmodellen op de eisen uit de AI-Act. Bommasani, Rishi et al. \u0026ldquo;Do Foundation Model Providers Comply with the EU AI Act?\u0026rdquo; https://crfm.stanford.edu/2023/06/15/eu-ai-act.html (2023).\nROOTS-corpus Om BLOOM te kunnen trainen moest er eerst een dataset samengesteld worden: het ROOTS-corpus. Ook hier weer lag de focus op openheid en ethiek. Van alle datasets die in ROOTS zijn opgenomen werden dataset cards gepubliceerd. De data zelf is opgeschoond en gededupliceerd. Persoonsgegevens als telefoonnummers, e-mailadressen en usernames op social media zijn zo veel mogelijk automatisch verwijderd. Zo is ROOTS uitgegroeid tot een dataset van 1,6 terabyte aan tekstdata in 46 natuurlijke talen, aangevuld met 13 verschillende programmeertalen.\nDie 46 verschillende talen vormen een nogal interessante mengelmoes. Uiteraard ontbreken high-resource Europese talen als Engels, Frans, Spaans en Portugees niet in dit toch grotendeels Europese project. Daarnaast maken ook Arabisch en Chinees2 acte de présence. Tenslotte zijn er bewust een aantal low-resource-talen aan de dataset toegevoegd, zoals meerdere talen uit de Niger-Congo-taalfamilie waarvoor maar weinig geschreven tekst beschikbaar is.\nTalen in het ROOTS-corpus. Grafiek uit de BLOOM model card.\nOpvallende ontbrekende talen? Allereerst: het Duits. Daarnaast het Russisch, en eigenlijk alle Slavische talen, net als de Scandinavische talen. En het Nederlands dus. Wel aanwezig: relatief kleine talen als het Catalaans en het Baskisch. Hoe kan dat?\nTaalselectie Hoe werd bepaald welke talen wel en welke talen niet meegenomen werden? Het antwoord is eigenlijk vrij simpel, maar vreemd genoeg niet te vinden in het paper dat het ROOTS-corpus beschrijft. In plaats daarvan komt het aan bod in het paper van BLOOM zelf, op pagina 10 en 11.\nLanguage Choices These considerations led us to an incremental process for choosing which languages were to be included in the corpus. We started with a list of eight of the world’s largest languages by number of speakers for which we did active outreach in the early stages of the project to invite fluent speakers to join the data efforts. Then, on the recommendation of language communities (Nekoto et al., 2020) we expanded Swahili in the original selection to the category of Niger-Congo languages, and Hindi and Urdu to Indic languages (Kunchukuttan et al., 2020). Finally, we proposed that any group of 3 or more participants fluent in an additional language could add it to the supported list if they would commit to selecting sources and guiding processing choices in the language in order to avoid common issues with corpora selected through automatic language identification without specific language expertise (Caswell et al., 2022).\nScao, Teven Le, et al. \u0026ldquo;Bloom: A 176b-parameter open-access multilingual language model.\u0026rdquo; arXiv preprint arXiv:2211.05100 (2022)\nVrijwilligers dus. Om precies te zijn: minimaal drie vrijwilligers die de taal vloeiend spreken en bereid waren om bronnen te selecteren, én bereid waren om te bewaken dat het verwerken van die bronnen op een goede manier gebeurde. Ik weet de details niet precies, maar ik schat het op hooguit enkele weken aan werk. Dat waren de kosten om als Nederlands mee te profiteren van een miljoeneninvestering. Blijkbaar waren er niet minimaal drie vrijwilligers beschikbaar die dat voor het Nederlands wilden of konden doen.\nGemiste kans? Had het ook anders kunnen lopen? Misschien wel. Ik hoorde zelf pas van het bestaan van BigScience toen het al te laat was. Vermoedelijk geldt dit ook voor anderen in Nederland of België die er graag aan hadden bijgedragen. Ja, als ik mee had willen doen had ik ergens die tijd vandaan moeten halen. Maar met een helder doel voor ogen en met het duidelijke belang dat we er als Nederland mee hebben was het vast wel gelukt. Het is niet vaak dat je met een kleine tijdsbesteding mee kunt liften op andermans miljoeneninvestering. Ik heb waarschijnlijk al langer in vergaderingen gezeten over consortia voor hypothetische toekomstige Nederlandstalige grote taalmodellen dan ik nodig gehad zou hebben om het Nederlands aan BLOOM toe te voegen.\nAan de andere kant: alle openheid ten spijt is BLOOM nou ook weer niet hét taalmodel geworden dat alle andere taalmodellen heeft doen vergeten. Met 176 miljard parameters is het inderdaad heel groot, maar BLOOM is van een eerdere generatie dan bijvoorbeeld LLaMA van Meta (70 miljard parameters), dat een stuk efficiënter met de parameters omgaat. In de 🤗 Open LLM Leaderboard, een ranglijst van best presterende grote taalmodellen, is BLOOM-178B niet eens opgenomen. Tekenend voor het gebrek aan interesse van de open source community, schat ik zo in. Een kleinere variant van BLOOM, BLOOM-7b1 met \u0026ldquo;maar\u0026rdquo; 7 miljard parameters, staat wel op de lijst, maar bevindt zich ergens in de onderste helft. BLOOMZ \u0026mdash; de chatversie van BLOOM \u0026mdash; komt ook niet op het leaderboard voor.\nBLOOM-7b1 op het 🤗 Open LLM Leaderboard.\nMaar wat meet dat leaderboard eigenlijk? Prestaties in het Engels. De grote open taalmodellen voor het Nederlands staan nog heel erg in de kinderschoenen. Er bestaat naar mijn weten niet eens zo\u0026rsquo;n leaderbord voor het Nederlands.3 En als er al een leaderboard zou bestaan voor open Nederlandstalige modellen: een hypothetische BLOOM dat ook op het Nederlands getraind zou zijn zou bovenaan de lijst prijken. In de lage landen der blinden zou éénoog koning zijn.\nLessen Welke lessen kan de Nederlandstalige AI-community wat mij betreft hieruit trekken?\nOm te beginnen: we moeten méédoen. De grote Amerikaanse techbedrijven zien Nederland en het Nederlands slechts als bijzaak, en geef ze eens ongelijk. Als sprekers van een kleine taal in een grote wereld moeten we opportunistisch zijn. Als we kunnen meeliften op een bestaand initiatief: capaciteit vrijmaken en doen! Vrijwilligers gezocht? Wij hebben ze klaarstaan! Niet alleen grootse projectplannen, maar vooral ook ijverige handjes.\nWe moeten voorkomen dat we een volgende keer weer de boot missen. Maar dat alleen is niet genoeg. We moeten als land \u0026mdash; en dus als overheid \u0026mdash; ook investeren in het samenstellen, opschonen en publiceren van Nederlandstalige datasets. Datasets voor het trainen, datasets voor het maken van chatbots en agents, datasets om prestaties te evalueren en om bias te meten. We moeten die datasets overal onder de aandacht brengen. Publiceren op alle plekken waar bedrijven en academici die een taalmodel willen trainen op zoek zijn naar data. Dus niet alleen op data.overheid.nl en de SURF Repository, maar ook op Github, op Hugging Face datasets en op r/MachineLearning. Pushen tot je er niet meer omheen kunt.\nNederlands als bijvangst. Niet per ongeluk, maar als nationale strategie.\nEn daar houdt het niet op. Als maatschappij moeten we ons afvragen waarom technologiebedrijven van eigen bodem momenteel niet dezelfde rol kunnen spelen voor het Nederlands die big tech wel speelt voor het Engels. Waar zijn de open modellen van Albert Heijn, Bol.com, Booking.com en Thuisbezorgd? En waarom kan het Nationaal Groeifonds wel meer dan 200 miljoen euro steken in het AINed-programma, maar kan ik vervolgens op hun website nul ontwikkelde open source datasets of modellen vinden?\nEn als ik dan toch bezig ben: denkt er überhaupt nog iemand aan taalmodellen voor het Fries?\nStrict gezien is het model niet open source. Het is door BigScience vrijgegeven onder de Responsible AI License (RAIL). Die stelt géén restricties aan hergebruik, distributie, commercialisering en aanpassingen, zolang je het maar niet inzet voor één van de restricted use cases in Appendix A. Van tevoren toestemming vragen is niet nodig.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSpecifiek: geschreven Vereenvoudigd Chinees\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nElke serieuze poging om een groot Nederlandstalig taalmodel te trainen zou eigenlijk moeten beginnen met het samenstellen van datasets waarmee je zo\u0026rsquo;n model fatsoenlijk zou kunnen evalueren.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://goingdutch.ai/nl/posts/bigscience-bloom/","summary":"Drie vrijwilligers. Een paar weken aan werk. Dat is wat er nodig was om een taal op te nemen in BigScience BLOOM, het open meertalige taalmodel met maar liefst 176 miljard parameters dat halverwege 2022 uitkwam. Het moest een open, meertalig alternatief voor GPT-3 worden. Uiteindelijk zijn er 46 talen van over de hele wereld beland in de dataset waarmee BLOOM getrained is. Ook relatief kleine talen als het Baskisch en het Catalaans kregen het voor elkaar om opgenomen te worden.","title":"De boot gemist: waarom het Nederlands ontbreekt in het belangrijkste open Europese taalmodel"},{"content":"Ik kan niet vaak publiekelijk iets uit de doeken doen over het soort zaken dat we bij het Nederlands Forensisch Instituut doen met behulp van AI, maar op de afgelopen EuroPython 2023 in Praag heb ik namens het NFI iets kunnen vertellen over een zaak die een paar jaar terug speelde en waar het NFI al eerder een persbericht over uitstuurde: het Threat-to-Life-project.\nPolitie kon live meelezen met criminelen Het was de politie in 2020 gelukt om live mee te kunnen lezen bij een aanbieder van zogenaamde cryptotelefoons: gemodificeerde telefoons die \u0026mdash; tegen een flinke betaling \u0026mdash; gebruikt werden om versleuteld te communiceren in het criminele circuit. Het was niet de eerste keer en ook niet de laatste dat de politie dat lukte. Het gebeurt dusdanig vaak dat er intussen zelfs een een overzichtslijstje bestaat van dergelijke operaties tegen aanbieders van cryptotelefoons.\nIn de praktijk blijkt dat sommige criminelen zich bijzonder veilig wanen bij het gebruik van dergelijke cryptotelefoons. Ze sturen dan ook zonder blikken of blozen de meest gevoelige en belastende berichten onverbloemd over de lijn. Communicatie is key in de zakenwereld blijkbaar, wat voor soort zaken je ook doet.\nDetecteren van threat-to-life-berichten Kunnen meelezen is één ding, maar als het gaat om een grote stroom berichten dan wil je dat sommige typen berichten wel echt op tijd door de politie beoordeeld worden. Als er bijvoorbeeld gesproken wordt over het voorbereiden van mishandelingen, ontvoeringen en liquidaties, dan moet er op tijd actie ondernomen kunnen worden om die te kunnen voorkomen. Daar was dus iets voor nodig: een threat-to-life-detector.\nZiedaar de uitdaging: train een classificatie-model dat threat-to-life berichten kan vinden in grote verzamelingen niet-threat-to-life-berichten afkomstig van cryptotelefoons. En hoewel de taak \u0026mdash; classificatie \u0026mdash; op zich niet zo vernieuwend is, is het nog niet triviaal om zo\u0026rsquo;n model van de grond te krijgen. Je moet immers een model maken dat kan omgaan met het soort taal dat in dit soort berichten voorkomt: informeel en doorspekt met straattaal en jargon. Heel wat anders dat de taal die tegenkomt als je Wikipedia scrapet dus.\nDaarnaast moet je voldoende trainingsdata weten te verzamelen \u0026mdash; voorbeelden van het soort berichten waar je naar op zoek bent. En die waren dus relatief zeldzaam in de grote stroom met andere berichten. Een beetje een kip-ei-probleem eigenlijk.\nEuroPython 2023 Hoe we die problemen opgelost hebben kan je zien in de live-opname van mijn praatje hieronder. Het was een relatief kort praatje voor een publiek van programmeurs, niet per sé van data scientists. Ik heb er daarom voor gekozen om niet heel diep op de details van de deep learning in te gaan, en in plaats daarvan wat meer tijd te besteden aan de context van het hele verhaal.\nMaar juist daarom is het denk ik een aardig kijkje in de keuken: het laat zien waar je tegenaan loopt bij de inzet van AI voor een zaak als deze.\nTientallen zware geweldsmisdrijven voorkomen En het resultaat? In het persbericht van de politie uit juli 2020 werd de voorlopige balans opgemaakt van de politieoperatie. Daaruit blijkt ook wat de politie heeft kunnen doen met de threat-to-life-signalen die uit het onderzoek voortkwamen.\nHieronder de voorlopige balans:\nMeer dan 100 verdachten aangehouden voor zeer zware delicten Bijna 20 miljoen euro cash in beslag genomen De inbeslagname van 8000 kilo cocaïne en ruim 1200 kilo crystal meth Er zijn 19 synthetische drugslabs ontmanteld Ook werden tientallen vuurwapens van straat gehaald Alleen al in Nederland werden de afgelopen maanden ruim 3000 signalen verwerkt die levensbedreigend leken. Door steeds tijdig in te grijpen heeft de politie tientallen zware geweldsmisdrijven kunnen voorkomen, waaronder op handen zijnde ontvoeringen, afpersingen, liquidaties en martelingen. Intussen, drie jaar later, is Europol nog steeds de score aan het bijhouden van de hele operatie. Volgens hun staat de teller intussen op meer dan 6.500 arrestaties en is er voor bijna 900 miljoen euro aan cash en tegoeden in beslag genomen.\nEn nu? Cryptotelefoons en ontcijferde berichten waren en zijn nog steeds zeer actueel in strafzaken. Dat wordt nogmaals geïllustreerd door een recent nieuwsartikel van NOS over hoe de digitale afdeling van het NFI honderden individuele crypotelefoons wist te kraken.\n","permalink":"https://goingdutch.ai/nl/posts/europython-2023-ttl/","summary":"Ik kan niet vaak publiekelijk iets uit de doeken doen over het soort zaken dat we bij het Nederlands Forensisch Instituut doen met behulp van AI, maar op de afgelopen EuroPython 2023 in Praag heb ik namens het NFI iets kunnen vertellen over een zaak die een paar jaar terug speelde en waar het NFI al eerder een persbericht over uitstuurde: het Threat-to-Life-project.\nPolitie kon live meelezen met criminelen Het was de politie in 2020 gelukt om live mee te kunnen lezen bij een aanbieder van zogenaamde cryptotelefoons: gemodificeerde telefoons die \u0026mdash; tegen een flinke betaling \u0026mdash; gebruikt werden om versleuteld te communiceren in het criminele circuit.","title":"Mijn praatje op EuroPython 2023: \"Threat to Life — Preventing Planned Murders with Python\""}]